{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are all the necessary libraries needed to get for the project\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "import sqlalchemy\n",
    "\n",
    "# This is the database location where all the extracted data will loaded into. I have to define it here to make available all functions\n",
    "db_location = f'mssql+pyodbc:ServerName//DBName?trusted_connection=tcon,&driver=ODBC Driver 17 for SQL Server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transform():\n",
    "    # Extracting from website(s)\n",
    "    url = 'https://www.worldometers.info/world-population/population-by-country/'   \n",
    "    country_list = []\n",
    "\n",
    "    try:\n",
    "#Extracting from the stock data API\n",
    "        _stock_price_api = 'Your API Endpoint goes here'\n",
    "        price = requests.get(_stock_price_api)\n",
    "        stk_data = price.json()\n",
    "        df_stk_price = pd.DataFrame.from_records(stk_data)\n",
    "        df_stk_price.rename(columns ={'$id':'Row_ID'}, inplace=True)\n",
    "        df_stk_price['Load_TradeDate'] = datetime.datetime.now() #.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "#Extracting from the bond data  API\n",
    "        bond_price_api = 'Your API Endpoint goes here'\n",
    "        bond_price = requests.get(bond_price_api)\n",
    "        bond_data = bond_price.json()\n",
    "        df_bond_price = pd.DataFrame.from_records(bond_data)\n",
    "        df_bond_price['Load_TradeDate'] = datetime.datetime.now()\n",
    "\n",
    "#Extracting from the etf data API\n",
    "        etfs_price_api = 'Your API Endpoint goes here'\n",
    "        etfs_price = requests.get(etfs_price_api)\n",
    "        etfs_data = etfs_price.json()\n",
    "        df_etfs_price = pd.DataFrame.from_records(etfs_data)\n",
    "        df_etfs_price['Load_TradeDate'] = datetime.datetime.now()\n",
    "\n",
    "#Here we fetching data from a website\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "        rows = soup.find('table', {'id':'example2'}).find('tbody').find_all('tr')\n",
    "        for row in rows:\n",
    "            dic = {}\n",
    "            dic['Country_Key'] = row.find_all('td')[1].text\n",
    "            dic['Country'] = row.find_all('td')[1].text\n",
    "            dic['Population(2020)'] = row.find_all('td')[2].text\n",
    "            dic['Yearly Cahnge'] = row.find_all('td')[3].text\n",
    "            dic['Net Change'] = row.find_all('td')[4].text\n",
    "            dic['Density(P/Km^2)'] = row.find_all('td')[5].text\n",
    "            dic['Land Area(Km^2)'] = row.find_all('td')[6].text\n",
    "            dic['Migrants(Net)'] = row.find_all('td')[7].text\n",
    "            dic['Fert.Rate'] = row.find_all('td')[8].text\n",
    "            dic['Med Age'] = row.find_all('td')[9].text\n",
    "            dic['Urban Pop%'] = row.find_all('td')[10].text\n",
    "            dic['World Share'] = row.find_all('td')[11].text\n",
    "            dic['Load_Txn_Date'] = datetime.datetime.now()\n",
    "\n",
    "            country_list.append(dic)\n",
    "        country_df = pd.DataFrame(country_list)\n",
    "        country_df['Country_Key'] = country_df['Country_Key'].str.replace(' ','')\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "#This function extracts the required values from a row with dictionary/list/tuple\n",
    "    def debt_dict(row):\n",
    "        r = ''\n",
    "        if isinstance(row, dict):\n",
    "            convert_dict = list(row.values())\n",
    "            r = convert_dict[0]\n",
    "            return r\n",
    "        elif isinstance(row, list):\n",
    "            return row[0]\n",
    "        elif isinstance(row, tuple):\n",
    "            return row[0]\n",
    "        else:\n",
    "            return row\n",
    "    try:       \n",
    "        pd_csv_local_file = pd.read_csv('employment_data.csv')\n",
    "        pd_csv_local_file['TxnDate'] = datetime.datetime.now()\n",
    "    \n",
    "        pd_xml_local_file = pd.read_xml('salary_data.xml')\n",
    "        pd_xml_local_file['TxnDate'] = datetime.datetime.now()\n",
    "    \n",
    "        pd_json_local_file = pd.read_json('user_cc_data.json')\n",
    "        pd_json_local_file['Load_TxnDate'] = datetime.datetime.now()\n",
    "        # There is a field that some of it rows contains a mix of dic, list, and tuple.\n",
    "        # So we will use the function (debt_dict) created above to uniquely make the corrections per row\n",
    "        pd_json_local_file[\"debt\"] = pd_json_local_file[\"debt\"].apply(debt_dict)\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    \n",
    "\n",
    "    return df_stk_price, country_df, pd_csv_local_file, pd_xml_local_file, pd_json_local_file \n",
    "\n",
    "def load():\n",
    "    try:\n",
    "#Creating a connection to SQL Server\n",
    "        sql_server_conn = sqlalchemy.create_engine(db_location)\n",
    "#Loading data to DB; it creates the table(s) if not exists! \n",
    "        extract_transform()[0].to_sql(\"nse_stk_price\", con = sql_server_conn, if_exists= \"append\", index=False)\n",
    "        extract_transform()[1].to_sql(\"world_population\", con = sql_server_conn, if_exists= \"replace\", index=False)\n",
    "        extract_transform()[2].to_sql(\"local_csv\", con = sql_server_conn, if_exists= \"append\", index=False)\n",
    "        extract_transform()[3].to_sql(\"local_xml\", con = sql_server_conn, if_exists= \"append\", index=False)\n",
    "        extract_transform()[4].to_sql(\"local_json\", con = sql_server_conn, if_exists= \"append\", index=False)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e8046ba043d00057e76b891a02c19473b4091277ee2cac39f399ed4c3ba2dcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
